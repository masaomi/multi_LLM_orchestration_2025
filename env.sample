# ==============================================
# Multi-LLM Orchestration Configuration
# ==============================================

# ----------------------------------------------
# AWS Bedrock Settings
# ----------------------------------------------
# AWS_REGION=us-east-1
# AWS_BEARER_TOKEN_BEDROCK=

# BEDROCK_MODELS=anthropic.claude-3-5-sonnet-20241022-v2:0

# ----------------------------------------------
# OpenRouter Settings
# ----------------------------------------------
# OPENROUTER_API_KEY=

# OPENROUTER_MODELS=anthropic/claude-3.5-sonnet,openai/gpt-4-turbo

# ----------------------------------------------
# Ollama Settings (Local)
# ----------------------------------------------
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODELS=llama3.1

# ----------------------------------------------
# Orchestration Settings
# ----------------------------------------------
MAX_ITERATIONS=3
CONSENSUS_THRESHOLD=0.75
PARALLEL_EXECUTION=true

